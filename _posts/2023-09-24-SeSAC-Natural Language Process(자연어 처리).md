---
layout: post
title: Natural Language Process(자연어 처리)
date: 2023-09-24 13:27 +0900
categories:
  - ETC
  - Tech
tags: 
math: true
---

## 1. 자연어 처리의 개념

### 1.1 정의
- 자연어의 의미를 분석하여 컴퓨터가 처리할 수 있도록 하는 일
- ex) 음성 인식, 요약, 번역, 감성 분석, 텍스트 분류, 질의 응답 시스텝, 챗복 등...
- '텍스트 분석' 이라고도 불리우나 '자연어 처리'라고 하면 인공지능을 이용한 분야라는 의미가 추가된다

### 1.2 주요 응용 분야

- 번역:
    - 구글 번역기 같은 도구들이 여러 언어 간의 실시간 번역을 가능케 함.
    - ex) "안녕하세요"를 영어로 번역하면 "Hello".
- 감성 분석:
    - 소셜 미디어 데이터를 분석하여 사용자의 감정 상태 파악.
    - ex) 상품 리뷰를 통한 긍정, 부정 의견 분석.
- 챗봇:
    - 사용자와의 대화를 통해 서비스를 제공.
    - ex) 고객 문의에 자동으로 응답하는 챗봇 서비스.
- 음성 인식:
    - 사용자의 음성 명령을 인식하여 동작 수행.
    - ex) "시리, 날씨 어때?"라고 물으면 날씨 정보 제공.
- 텍스트 요약:
    - 긴 문서의 주요 내용을 짧게 요약.
    - ex) 뉴스 기사의 핵심 내용 요약.
- 질의 응답 시스템:
    - 사용자의 질문에 대해 정확한 답변 제공.
    - ex) "세계에서 가장 큰 도시는 어디인가요?"에 대한 답변 제공.

### 1.3 자연어 처리의 중요성

- 다양한 산업 분야에서의 활용:
    - 유통, 금융, 제조 등 다양한 분야에서 NLP 기술 활용.
- 인력 수요와 기회:
    - 중급 이상의 NLP 전문가 부족, 해당 분야에 대한 수요와 기회 증가.
- 오픈 소스 및 자원의 공개:
    - 성능 좋은 NLP 모델과 도구의 오픈 소스 공개로 접근성 향상.

### 1.4 한국어 NLP의 특징과 어려움

- 교착어:
    - 한국어는 교착어로 분류, 형태소 분석 중요.
- 띄어쓰기:
    - 한국어에서는 띄어쓰기 규칙이 복잡하고, 일관성이 떨어짐.
- 어순:
    - 한국어의 어순은 상대적으로 자유로움.
- 주어 생략:
    - 문장 내에서 주어가 생략되는 경우가 자주 발생.
- 데이터와 모델의 다양성 부족:
    - 한국어에 특화된 모델과 데이터셋의 다양성이 영어에 비해 부족함.

## 2. 텍스트 전처리

### 2.1 토큰화 (Tokenization)

- 토큰화는 텍스트를 의미 있는 단위로 나누는 과정으로, 이를 통해 컴퓨터가 텍스트를 이해할 수 있게 됨.
- 종류와 특징: 단어 토큰화, 문장 토큰화, 형태소 토큰화 등이 있으며, 각각의 특징과 사용 상황이 다름.
- 도구 및 라이브러리: NLTK, KSS, Mecab, Khali, KOMORAN, Soynlp 등이 있음.

### 2.2 정수 인코딩 (Integer Encoding)

- 각 단어에 고유한 정수를 부여하여, 텍스트를 정수의 시퀀스로 변환하는 과정.
- 단어 집합 (Vocabulary)의 생성: 중복이 허용되지 않는 모든 단어들의 집합을 만들어, 단어에 정수를 부여함.
- OOV 문제와 해결 방안: 단어 집합에 없는 단어는 OOV로 처리하며, 이를 해결하기 위한 다양한 방법이 있음.

### 2.3 패딩 (Padding)

- 다양한 길이의 문장을 동일한 길이로 맞춰주기 위해 패딩을 사용함. 이를 통해 기계가 병렬 연산을 수행할 수 있음.

### 2.4 텍스트의 벡터화

- 텍스트 데이터를 벡터로 변환하는 방법: One-Hot Encoding, Document Term Matrix, TF-IDF 등의 방법을 사용하여 텍스트 데이터를 벡터로 변환함.

## 3. 단어 임베딩

### 3.1 단어 임베딩의 개념

- 단어 임베딩은 단어를 고차원의 벡터로 표현하는 것으로, 이를 통해 단어 간의 유사도를 계산할 수 있음.
- 단어 임베딩의 종류와 특징: Word2Vec, GloVe, FastText 등의 다양한 단어 임베딩 방법이 있음.

### 3.2 임베딩 학습 방법

- 대량의 텍스트 데이터를 사용하여 단어 임베딩을 학습할 수 있음. 이를 통해 비지도 학습 방식으로 단어의 벡터 표현을 얻을 수 있음.

## 4. 문장 임베딩과 문맥화 임베딩

### 4.1 문장 임베딩의 개념

- 문장 임베딩은 전체 문장을 고차원의 벡터로 표현하는 것으로, 이를 통해 문장 간의 유사도를 계산할 수 있음.
- 문장 임베딩의 종류와 특징: Doc2Vec, Sent2Vec, InferSent 등의 다양한 문장 임베딩 방법이 있음.

### 4.2 문맥화 임베딩의 개념

- 문맥화 임베딩은 단어의 문맥을 고려하여 단어를 벡터로 표현하는 방법으로, 이를 통해 동일한 단어라도 문맥에 따라 다른 벡터를 갖게 됨.
- 문맥화 임베딩의 종류와 특징: ELMo, BERT, GPT 등의 다양한 문맥화 임베딩 방법이 있음.

## 5. 텍스트 분류와 감성 분석

### 5.1 텍스트 분류의 개념

- 텍스트 분류는 주어진 텍스트를 미리 정의된 카테고리 중 하나로 분류하는 작업임.
- 텍스트 분류의 응용: 스팸 메일 필터링, 뉴스 카테고리 분류, 감성 분석 등 다양한 분야에서 활용됨.

### 5.2 감성 분석의 개념

- 감성 분석은 텍스트에서 나타나는 저자의 감정이나 태도를 파악하는 과정임.
- 감성 분석의 응용: 제품 리뷰 분석, 소셜 미디어 감정 분석 등 다양한 분야에서 활용됨.