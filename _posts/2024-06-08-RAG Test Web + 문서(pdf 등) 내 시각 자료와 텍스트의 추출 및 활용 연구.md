---
layout: post
title: RAG Test Web
date: 2024-06-08 22:43 +0900
categories:
  - Project
  - RAG
tags: 
math: true
---


# Web 

## 기술:

### **Web Frameworks and Servers:**

- FastAPI + Gunicorn

### **Containerization:**

- Docker

### **AI Framework:**

- Langchain
- LlamaIndex
- Ollama


# 연구
## 문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용


- https://www.youtube.com/watch?v=U_f4-Br3_Y0

- [Medium]Multimodal RAG using Langchain Expression Language And GPT4-Vision]([https://medium.aiplanet.com/multimodal-rag-using-langchain-expression-language-and-gpt4-vision-8a94c8b02d21](https://medium.aiplanet.com/multimodal-rag-using-langchain-expression-language-and-gpt4-vision-8a94c8b02d21))
- [[Langchain]How to pass multimodal data directly to models](https://python.langchain.com/v0.2/docs/how_to/multimodal_inputs/)
- [https://paperswithcode.com/paper/llava-uhd-an-lmm-perceiving-any-aspect-ratio](https://paperswithcode.com/paper/llava-uhd-an-lmm-perceiving-any-aspect-ratio)
- [https://huggingface.co/docs/transformers/en/model_doc/llava](https://huggingface.co/docs/transformers/en/model_doc/llava)
- [https://github.com/langchain-ai/langchain/blob/master/cookbook/multi_modal_output_agent.ipynb](https://github.com/langchain-ai/langchain/blob/master/cookbook/multi_modal_output_agent.ipynb)