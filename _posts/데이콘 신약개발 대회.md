---
layout: post
title: 데이콘 신약개발 대회
date: 2023-09-07 14:18 +0900
categories:
  - Project
  - 데이콘
tags: []
math: true
---

## Intro: 
최근에 참가하고 있는 신약개발 AI 경진대회에서 겪었던 어려움-해결방법, 접근 방법이나 시도를 정리해보고자 한다




## SMILES(Simplified Molecular Input Line Entry System)란?

- **정의**: SMILES는 Simplified Molecular Input Line Entry System의 약자로, 분자의 구조를 텍스트 형식으로 간단하게 표현하는 방법이다.
- **특징**: SMILES는 어떤 화합물의 구조도 짧은 문자열로 표현할 수 있어 데이터 저장 및 처리에 매우 유리하다.
- **용도**: 컴퓨터 시스템에서 분자 구조를 쉽게 읽고 쓸 수 있도록 설계되어, 화학 및 생물학 연구에 널리 쓰이고 있다.

이번 대회에서는 SMILES 문자열을 활용하여 분자의 구조와 특성을 파악하고, 그 정보를 바탕으로 신약의 효능을 예측하는 모델을 개발하려고 한다.


## SMILES 처리 방법

### 1. 분자 지문 (Molecular Fingerprints)
1. 데이터 처리: SMILES로부터 분자 지문을 추출
2. 모델 학습: 예를 들어 RandomForestRegressor 사용
3. 하이퍼파라미터 최적화: GridSearchCV 또는 RandomizedSearchCV 사용

- 장점: 빠르고, 이해하기 쉽고, 다양한 머신러닝 알고리즘에 적용하기 쉽다
- 단점: 정보의 손실이 있을 수 있고, 분자 구조의 모든 세부 정보를 담기 어렵다

### 2. Mol2Vec
1. 데이터 처리: SMILES의 각 부분에 대한 임베딩을 생성
2. 모델 학습: 예를 들어, RandomForestRegressor 사용
3. 하이퍼파라미터 최적화

- 장점: 더 복잡한 패턴을 포착할 수 있다
- 단점: 학습 시간이 오래 걸릴 수 있고, 해석하기 어려울 수 있다

### 3. 그래프 기반 접근법
1. 데이터 처리: 분자를 그래프로 변환
2. 모델 학습: Graph Neural Networks (GNNs) 사용
3. 하이퍼파라미터 최적화

- 장점: 분자 구조의 복잡성을 더 잘 모델링할 수 있다
- 단점: 계산 비용이 높고, 구현이 복잡할 수 있다

### 4. One-hot Encoding
1. 데이터 처리: SMILES 문자열의 각 문자를 one-hot 벡터로 인코딩
2. 모델 학습: RandomForestRegressor 사용
3. 하이퍼파라미터 최적화

- 장점: 간단하고 빠르다
- 단점: SMILES 문자열의 길이가 다르면 패딩이 필요하고, 문자열의 길이가 길 경우 차원이 높아진다

### 5. Sequence Models (RNN, LSTM, GRU 등)
1. 데이터 처리: SMILES 문자열을 시퀀스로 변환
2. 모델 학습: LSTM 또는 GRU 사용
3. 하이퍼파라미터 최적화

- 장점: 시퀀스 데이터의 내재된 의미를 잘 포착할 수 있다
- 단점: 학습 시간이 오래 걸리고, 복잡한 모델 구조를 필요로 한다

### 6. Transformer-based models
1. 데이터 처리: SMILES 문자열을 시퀀스로 변환
2. 모델 학습: Transformer architecture (e.g., BERT for chemistry) 사용
3. 하이퍼파라미터 최적화

- 장점:
    - 깊은 자기 주의 메커니즘 덕분에 복잡한 패턴 및 의존성을 포착할 수 있다.
    - 장거리 의존성을 잘 처리한다.
    - 전이 학습(transfer learning)을 통해 사전 학습된 모델을 활용할 수 있어 데이터가 적은 상황에서도 유용하다.
    - SMILES 문자열의 다양한 특성과 복잡성을 포착할 수 있다.
- 단점:
    - 대규모 모델이 필요할 수 있어 학습 및 추론에 많은 계산 리소스가 필요하다.
    - 해석하기 어려울 수 있다.
    - 모델의 크기와 복잡성으로 인해 학습 시간이 오래 걸릴 수 있다.


## AUTO-ML(Pycaret)

> Pycaret을 사용해보는 도중`HLM`이나 `MLM` 데이터가 있을때 훨씬 예측을 잘 한다는 사실을 깨달았다
>
> 따라서, `MLM`이나 `HLM`을 먼저 예측 한 뒤, 그 데이터를 다른 하나를 예측하는데 사용하면 RMSE값을 유의미있게 낮출 수 있다고 예상할 수 있었다
>
> `MLM`과 `HLM`중 어느 데이터를 먼저 예측하면 최상의 결과를 얻을 수 있을까 실험해보았다


양 데이터 존재시:

| target | API        | RMSE    | $R^2$  | Model |
| ------ | ---------- | ------- | ------ | ----- |
| MLM    | Functional | 25.0165 | 0.4993 | Orthogonal Matching Pursuit      |
| MLM    | OOP        | 25.0165 | 0.4993 | Orthogonal Matching Pursuit      |
| HLM    | Functional | 25.7050 | 0.4936 |  Orthogonal Matching Pursuit     |
| HLM    | OOP        | 25.0165 | 0.4993 | Orthogonal Matching Pursuit      |

> 얼핏보기엔 유효해 보이나, 결론은 큰 차이가 없는것 같다. 예측된 MLM을 feature로 사용한들 예측모델의 성능이 좋아야 하는데, MLM 예측 모델의 성능을 높히는 기법들은 결국 똑같이 HLM에도 적용될 수 있기 때문이다. 이 가설도 확인해 보려 한다.


