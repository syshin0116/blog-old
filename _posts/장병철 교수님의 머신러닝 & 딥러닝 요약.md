# 1. Machine Learning

1. 지도 학습(Supervised-Learning)
	- Target(Label)이 있음
	- ex) K-Means를 제외한 나머지
2. 비지도 학습(Unsupervised-Learning)
	- 라벨이 없음 → 성능 평가 불가
	- ex) K-means
3. 강화 학습(Reinforcement-Learning)
	- 라벨이 없음
	- 경험을 기반으로 학습해나감(?)
## 1-1. 모델(Model)
### 수학적 분류

1. **유사성 기반 학습 (Similarity-based Learning)**:
	- 새로운 데이터 포인트와 가장 유사한 학습 데이터 포인트를 찾아서 예측을 하는 방법
	- 예: KNN(K-Nearest Neighbors), K-Means
2. **정보 기반 학습 (Information-based Learning)**:
	- 데이터에서 가장 유용한 특성(정보)을 찾아내서 예측 모델을 구성
	- 예: Decision Trees, Random Forest
3. **확률 기반 학습 (Probability-based Learning)**:
	- 데이터의 확률 분포를 학습하여 예측을 하는 방법
4. **에러 기반 학습 (Error-based Learning)**:
	- 예측의 에러를 최소화하도록 모델을 조정하는 방법
	- 예: Linear Regression, Logistic, Lasso, Ridge, SGD(Stochatic Gradient Descent)

## 1-2. 성능 평가 & 비용 함수(Cost-Function)

### 성능 평가
1. **$R^2$ : 회귀 모델 평가
2. Accuracy: 분류 모델 평가

#### **$R^2$ (결정 계수)**
$$R^2 = 1-\tfrac{오차^2}{편차^2} 
	= 1-\tfrac{\sum (예측값 - 실제값)^2}{\sum (실제값평균-실제값)^2}
	= 1-\tfrac{\sum (\widehat{y} - y)^2}{\sum (\bar{y}-y)^2}$$
- **해석**:
	- 값이 0과 1 사이에 있으며, 1에 가까울수록 모델이 데이터의 변동성을 잘 설명한다는 것을 의미
	- 반면, 0에 가까울수록 모델의 설명력이 떨어진다는 것을 의미

#### 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 Score

![](https://i.imgur.com/pRzUU1i.png)

##### Accuracy (정확도)
 - 전체 예측 중 올바르게 예측된 비율
$$
\text{Accuracy} = \frac{\text{올바르게 예측된 샘플 수}}{\text{전체 샘플 수}}
$$

##### Precision (정밀도)
- 양성(positive)으로 예측된 샘플 중 실제로 양성인 비율
$$
\text{Precision} = \frac{\text{진짜 양성 (TP)}}{\text{진짜 양성 (TP) + 거짓 양성 (FP)}}
$$

##### Recall (재현율)
- Recall은 실제 양성(positive) 중 양성(positive)으로 올바르게 예측된 비율


$$
\text{Recall} = \frac{\text{진짜 양성 (TP)}}{\text{진짜 양성 (TP) + 거짓 음성 (FN)}}
$$

|     | o, o, o, o, o, o, o, o, x, x | 정확도(A) | 정밀도(P) | 재현률(R) |
|:--- |:---------------------------- |:--------- |:--------- |:--------- |
| A   | o, o, o, o, o, o, o, o, o, x | 9/10      | 8/9       | 8/8       |
| B   | o, o, o, o, o, o, o, x, x, x | 9/10      | 7/9       | 7/8       |
##### F1 Score (F1 점수)
- Precision과 Recall의 조화 평균
$$
\text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$
### 비용 함수(Cost-Function)
1. MSE / RMSE
2. log-loss
3. hinge

- MSE는 예측 오차의 제곱 평균을 나타내며, 값이 낮을수록 좋다.
- RMSE는 MSE의 제곱근으로, 예측 오차의 실제 크기를 나타낸다.
- **$R^2$는 모델이 데이터의 변동성을 얼마나 잘 설명하는지를 나타내는 지표로, 1에 가까울수록 좋다.

#### 평균제곱근 오차, RMSE(Root Mean Squared Error)
$$\sqrt{\frac{1}{n}\sum_{i=1}^{n}((y-\widehat{y})^2)}$$ 1. $n$: 데이터 포인트의 개수
2. $y_{i}$: 실제 관측된 값(데이터 포인트), 여기서 $i$는 데이터 포인트의 인덱스
3. $\widehat{y_{i}}$: 모델이 예측한 값,  실제 관측된 값과 모델이 예측한 값 사이의 차이
4. $(y_{i}-\widehat{y_{i}})^2$: 각 데이터 포인트에 대한 오차의 제곱. (실제 값과 예측 값의 차이를 제곱한 값)
5. $\sum_{i=1}^{n}$: 모든 데이터 포인트에 대해 오차 제곱을 합산하는 부분. ($i$는 1부터 $n$까지 변화한다.)
6. $\frac{1}{n}$: 데이터 포인트의 개수로 나눠줌으로써 오차 제곱의 평균을 계산
7. $\sqrt{\text{...}}$: 앞서 계산한 평균 오차 제곱을 제곱근을 취해 RMSE를 계산. (이것은 오차의 제곱 평균의 제곱근으로, 실제 값과 예측 값 사이의 평균적인 오차 크기를 나타낸다.)

- 해석:
	- 예측 오차의 크기를 직관적으로 해석하기 쉽게 만듬
	- 값이 낮을수록 모델의 성능이 좋다
#### 평균제곱 오차, MSE(Mean Squared Error)
$$\frac{1}{n}\sum_{i=1}^{n}((y-\widehat{y})^2)$$
- **해석**: 
	- MSE는 예측 오차의 제곱 평균
	- RMSE에 제곱근을 취하지 않은 것
	- 값이 낮을수록 모델의 성능이 좋다
	- 오차를 나타내기 때문에 정확한 평가지표가 될 수 없다



#### 로지스틱 회귀의 비용 함수(Cost Function):
$$cost F = -(Plog_{e}\widehat{P})$$

- $P$: 실제 관측값을 나타낸다. 이 값은 0 또는 1일 수 있으며, 각 데이터 포인트의 실제 클래스를 나타낸다.
- $\widehat{P}$: 모델의 예측 확률을 나타낸다. 이 값은 로지스틱 함수를 통해 계산된 예측 확률이며, 0과 1 사이의 값이다.
- $\log_e$: 자연 로그(natural logarithm)를 나타낸다. 자연 로그는 $e$ (2.71828...)를 밑으로 하는 로그를 의미한다.

$$ J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \left[ p \log_{e}(\widehat{p})) + (1 - p) \log_{e}(1 - (\widehat{p})) \right] $$

##### 로지스틱 함수(Logistic Function), 시그모이드 함수(Sigmoid Function)
$$
h_\theta(x) = \frac{1}{1 + e^{-z}}
$$

* 미분 가능하면서 classification을 위해 고안된 함수
* `z` 에 선형회귀식 대입
* 선형회귀식을 z자리에 넣으면 곡선으로 바뀐다
* 로지스틱 함수의 값은 0에서 부터 1 사이의 값이 나온다
$$선형회귀식 = (W_{1}X_{1} + W_{2}X_{2}\cdots +W_{0}))$$
![](https://i.imgur.com/Ti1bntp.png)



## 1-3 트리의 앙상블(Ensemble)
- 목표: 과적합을 방지하고 모델의 분산을 줄여 전반적인 예측 성능을 향상
### Bagging(Bootstrap Aggregating)
- 정의: 복원추출 (bootstrapping)을 통해 생성된 여러 개의 서브셋을 활용해 독립적으로 여러 모델을 학습시키는 앙상블 방법
	- 부트스트랩: 
		- 데이터 세트에서 중복을 허용하여 데이터를 세는 기법
		- 1000개의 샘플이 있을 때, 먼저 1개를 뽑고 다시 가방에 넣어 그다음 샘플을 뽑는다
- 작동 원리:
	1. 원본 데이터 세트에서 복원추출을 통해 여러 개의 서브셋을 생성(부트스트랩)
	2. 각 서브셋에 대해 독립적으로 모델 학습
	3. 회귀 문제에서는 예측값의 평균을, 분류 문제에서는 투표 방식을 사용해 최종 예측
- 대표적인 알고리즘: Random Forest, Extra Tree
### Boosting
- 정의: Boosting은 약한 학습기를 순차적으로 훈련시켜 강한 학습기를 만드는 앙상블 방법이다.
- 작동 원리:
	1. 초기에는 모든 데이터 포인트에 동일한 가중치를 부여한다.
	2. 약한 학습기를 훈련시켜 오류를 줄인다.
	3. 잘못 분류된 데이터 포인트에 더 높은 가중치를 부여하고 다시 학습한다.

- 대표적인 알고리즘:  SGD, XG Boost, Light GBM, Histogradient Boosting, 그래디언트 부스팅 (Gradient Boosting)
### 요약
- 트레이닝 데이터에 대한 성능은 기본적으로 boosting이 bagging보다 더 좋다
- 배깅에 비해 부스팅이 과적합에 취약하다
* 하지만 overfitting될 가능성이 더 높다

### 혼잡도 & 불확실성 측정 방법 2가지
- 어떤 분할이 데이터를 더 잘 구분할 수 있는지를 평가
#### 정보 이득(Information Gain) & 엔트로피(Entropy)

##### 정보 이득(Information Gain)
- 특정 특성으로 노드를 분할할 때 얻게 되는 정보의 양
- 부모 노드의 엔트로피와 자식 노드들의 **가중 평균 엔트로피의 차이**로 계산
- 즉, 정보이득은 특정 분할을 통해 얼마나 많은 엔트로피(불확실성)를 감소시킬 수 있는지를 나타낸다

$$
\text{Information Gain} = \text{Entropy(parent)} - \sum \left( \frac{\text{no. of samples in child}}{\text{no. of samples in parent}} \times \text{Entropy(child)} \right)
$$
##### 엔트로피(Entropy)
- 데이터의 불확실성 혹은 혼잡도를 측정하는 지표
- 특정 노드의 데이터가 모두 동일한 클래스에 속하면 엔트로피는 0, 여러 클래스에 균등하게 분포되어 있을 경우 최대값

다중 클래스:
$$ \text{Entropy}(S) = - \sum_{i=1}^{c} p_i \log_2(p_i) $$
두 개의 클래스:
$$ \text{Entropy}(S) = -p_+ \log_2(p_+) - p_- \log_2(p_-) $$
- $p_+$: 양성 샘플의 비율
- $p_-$: 음성 샘플의 비율
- $c$: 클래스의 개수

##### Gini 불순도(Gini Impurity)
- 임의의 데이터 집합 내의 다양한 클래스의 분포를 측정하여 얼마나 '순수한' 상태인지를 나타내는 지표

다중 클래스:

$$Gini(D)=1−∑_{i=1}^c​p_{i}^2​$$
두 개의 클래스:
$$
\text{Gini Impurity}(S) = 1 - (p_+^2 + p_-^2)
$$
여기서,
- $D$: Data의 약자이며, 이 집합은 다양한 클래스의 샘플을 포함
- $S$: Subset의 약자이며, Data와 Subset은 교재에 따라 다르게 표시될 뿐 같은 의미로 사용
- $c$: 클래스의 개수
- $p_{i}$​: 데이터 집합 내에서 클래스 $i$에 속하는 샘플의 비율

> 예를 들어, 레드와인이 4개, 화이트와인이 6개라면?
> 
> $p_{red}=\frac{4}{10} =0.4$  및 $p_{white}=\frac{6}{10}=0.6$$
> 
> $Gini(D)=1−(p_{red}^2​+p_{white}^2​)$


### 주성분 분석(PCA: Principal Component Analysis)
정의:
- 고차원의 데이터를 저차원의 데이터로 변환하는 차원 축소 방법

목적:
- 데이터의 차원을 줄여 계산 효율성을 높임
- 데이터 시각화를 용이하게 함
- 노이즈를 제거하여 데이터의 특징을 더 잘 나타내게 함

> 작동 원리:
> 1. 데이터의 공분산 행렬을 계산
> 2. 공분산 행렬의 고유값과 고유벡터를 찾음
> 3. 고유값이 큰 순서대로 K개(축소하려는 차원 수)의 고유벡터를 선택
> 4. 선택된 고유벡터를 사용하여 원래 데이터를 변환
# 2. Deep Learning

PCA
Sequential
Perceptron
Mini-Batch
Layer
sparse-categorical-crossentropy

질문: 
- PCA가 비지도 챕터에 들어있는데, 지도 학습에는 잘 안쓰이는지?
- 