---
layout: post
title: 문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용 1
date: 2024-07-22 18:00 +0900
categories:
  - ETC
  - 세미나
tags: 
math: true
---

# 문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용

신승엽

## 배경

### 시각 자료의 중요성
- 시각 자료는 문서의 이해와 정보 전달을 돕는 중요한 요소
- 특히, 그래프, 표, 이미지 등은 복잡한 정보를 쉽게 전달하는 수단으로 사용되기 때문에, 중요한 정보를 담고 있는 경우가 많음

### PDF 에서 시각 정보 추출이 어려운 이유


### 한자연 Agent에서의 기본 PyPDF 사용 결과

![](https://i.imgur.com/IGfnuxc.png)


![](https://i.imgur.com/ZMTUlU3.png)


---

## 시각 자료 활용 방법

### 1. Unstructured Loader와 같은 PDF Loader 활용

#### 1-1. 단순 변환
- **이미지 저장**: PDF 파일에서 추출된 이미지를 파일로 저장
- **이미지 경로 삽입**: 저장된 이미지의 파일 경로를 해당 이미지를 설명하는 텍스트 사이에 삽입
- **벡터스토어에 저장**: 텍스트와 이미지 경로를 포함한 데이터를 벡터스토어에 저장

![[Excalidraw/Method1]]
#### 2. Multi-Modal RAG 

![](https://i.imgur.com/rqUfDaj.png)

1. Retrieve Raw Image
	- 다중 모달 임베딩(ex: CLIP)을 사용하여 이미지와 텍스트를 임베딩
	- 유사성 검색을 사용하여 둘 다 검색
	- 다중 모달 LLM에 원본 이미지와 텍스트 조각을 전달하여 답변 합성
2. Retrieve Image Summary
	- 다중 모달 LLM(ex: GPT-4V, GPT-4o, LLaVA, FUYU)를 사용하여 이미지에서 텍스트 요약 생성
	- 텍스트 임베딩, 검색
	- LLM에 텍스트 조각을 전달하여 답변을 합성
3. Retrieve Raw Image + Image Summary
	- 다중 모달 LM(ex: GPT-4V, GPT-4o, LLaVA, FUYU)을 사용하여 이미지에서 텍스트 요약 생성
	- 원본 이미지에 대한 참조와 함께 이미지 요약을 임베딩하고 검색
	- 다중 모달 LLM에 원본 이미지와 텍스트 조각을 전달하여 답변을 합성



### 2. Colpali

### **연구내용**

![https://cdn-uploads.huggingface.co/production/uploads/60f2e021adf471cbdf8bb660/T3z7_Biq3oW6b8I9ZwpIa.png](https://cdn-uploads.huggingface.co/production/uploads/60f2e021adf471cbdf8bb660/T3z7_Biq3oW6b8I9ZwpIa.png)

### Models

- SigLIP: 바닐라 모델
    - vision-language bi-encoder model
    - image-text 쌍으로 사전학습
- BiSigLIP: +파인튜닝
    - figure retrival + table retrieval
    - 복잡한 형식 이해 능력 향상
- BiPali: +LLM
    - LLM 모델: PaliGemma [https://arxiv.org/pdf/2407.07726](https://arxiv.org/pdf/2407.07726)
- ColPali: +Late Interaction

### ColBert: Late Interaction for efficient and effective passage search

![https://i.imgur.com/IxwVgOJ.jpeg](https://i.imgur.com/IxwVgOJ.jpeg)

장점:

- 후기 상호작용은 쿼리와 문서 간에 보다 세분화된 매칭 프로세스를 가능하게 합니다. 쿼리의 각 구성 요소를 문서의 각 구성 요소와 비교함으로써 시스템은 보다 전체적인 접근 방식으로는 놓칠 수 있는 관련성의 뉘앙스를 포착할 수 있습니다.
- **인코딩과 상호작용 단계를 분리함으로써 후기 상호작용 모델은 쿼리와 독립적으로 커멘트 임베딩을 미리 계산하고 색인을 생성할 수 있습니다. 따라서 임베딩 생성의 계산 집약적인 부분이 이미 완료되었으므로 쿼리 단계에서 모델의 효율성이 매우 높아집니다.**
- 쿼리가 실제로 수행될 때까지 비교 과정이 연기되기 때문에, 후기 연동 모델은 전체 문서 코퍼스를 재처리할 필요 없이 동적 및 임시 쿼리를 쉽게 처리할 수 있습니다.

가능성이 충분히 보이지만, 아직 영어와 불어만 지원한다는 점, 그리고 페이지 단위까지밖에 검색이 되지 않는다는 점에서 아쉽다. 하지만, open source인만큼 추후 기대가 크고, 현재로썬 다른 방식과 혼합하여 쓰는 방식도 충분히 고려해볼만 하다

### 참고 자료:




## 추가
ChartGemma: Visual Instruction-tuning for Chart Reasoning in the Wild
- PapersWithCode:  https://paperswithcode.com/paper/chartgemma-visual-instruction-tuning-for
- HuggingFace Space Demo: https://huggingface.co/spaces/ahmed-masry/ChartGemma

## 발표 자료
https://docs.google.com/presentation/d/1X4UjKIj8Hf5h80QgvwKSLM2jNsW_X3YIlArYWhyv5UU/edit?usp=sharing

## 참고 자료:
- https://medium.com/@abatutin/is-the-langchain-multi-vector-retriever-worth-it-0c8565e8a8fd
- [\[유튜브 테디노트\] GPT4o를 사용하여 PDF 내 표와 이미지를 참고하여 답변하는멀티모달 RAG](https://youtu.be/U_f4-Br3_Y0?si=Q-cRhXih576BoDcg)
- https://blog.langchain.dev/semi-structured-multi-modal-rag/
- https://arxiv.org/pdf/2407.01449v2

- https://github.com/illuin-tech/vidore-benchmark
- https://arxiv.org/abs/2407.01449
- https://huggingface.co/spaces/vidore/vidore-leaderboard
- [https://www.youtube.com/watch?v=0C0FL0iFd1E](https://www.youtube.com/watch?v=0C0FL0iFd1E)
- Paper: [https://arxiv.org/pdf/2407.01449v2](https://arxiv.org/pdf/2407.01449v2)
- HuggingFace Model: [https://huggingface.co/vidore](https://huggingface.co/vidore)
- Github: [https://github.com/illuin-tech/colpali](https://github.com/illuin-tech/colpali)