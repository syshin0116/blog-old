---
layout: post
title: ZoeDepth
date: 2023-12-19 23:22 +0900
categories:
  - ETC
  - Paper-Summary
tags:
  - zoedepth
math: true
---

# ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth

- paper: [https://arxiv.org/pdf/2302.12288.pdf](https://arxiv.org/pdf/2302.12288.pdf)
- github: [https://github.com/isl-org/ZoeDepth](https://github.com/isl-org/ZoeDepth)
## 목표와 도전 과제

- 상대적 및 측정적 깊이 추정 방법을 통합하여 보다 정밀하고 신뢰할 수 있는 깊이 정보를 제공
- 다양한 환경에서의 깊이 추정의 정확도를 개선
- 특히 도시 환경과 같이 복잡한 실외 환경에서의 성능 향상
	- 이를 위해 다양한 데이터셋에서 사전 학습된 모델을 사용
	- 특정 데이터셋에서 미세 조정하여 모델의 일반화 능력 강화


## 방법론

- Relative 및 Metric Depth Estimation의 결합을 통해 깊이 추정 방법론 혁신
- ZoeDepth는 MiDaS 모델을 기반으로 하여 깊이 추정의 정확도 향상
- 새로운 'metric bins module'을 통한 깊이 추정의 개선
    - 이 모듈은 깊이 추정의 정밀도를 높이는 데 중요한 역할을 함
    - 다양한 환경에서의 깊이 추정 정확도를 위해 설계됨

## 모델 아키텍처

- 기존 MiDaS 깊이 추정 프레임워크와 DPT 아키텍처를 결합하여 구축
- RGB 이미지를 처리하여 다양한 해상도에서 깊이 정보 추출
- MiDaS 디코더는 상대적 깊이 정보를 생성하기 위해 다양한 크기의 특징 맵을 결합
- 'metric bins module'은 픽셀별 깊이 bin 중심을 계산하고 이를 선형 결합하여 측정적 깊이 정보를 도출
- 다양한 트랜스포머 백본, 예를 들어 BEiT와 Swin Transformer를 MiDaS 인코더에 적용하여 깊이 추정의 정확도 및 성능 개선

![](https://i.imgur.com/te28KRN.png)


## 데이터셋과 사전 훈련

- 12개의 다양한 데이터셋을 사용
- 주요 데이터셋으로는 실내 환경에는 NYU Depth v2, 실외 환경에는 KITTI가 사용
- 추가적으로 Relative Depth Estimation을 위한 백본 사전 훈련으로 HRWSI, BlendedMVS, ReDWeb, DIML-Indoor, 3D Movies, MegaDepth, WSVD, TartanAir, ApolloScape, IRS 등의 데이터셋 사용
- 이들 데이터셋은 모델의 다양한 환경에 대한 일반화 능력을 강화하기 위해 선택


## Loss Function and Evaluation Metrics

1. Absolute Relative Error (REL): 
$$
\quad \text{REL} = \frac{1}{M} \sum_{i=1}^{M} \left| \frac{d_i - \hat{d}_i}{d_i} \right|
$$
2. Root Mean Squared Error (RMSE):
$$
\quad \text{RMSE} = \sqrt{\frac{1}{M} \sum_{i=1}^{M} \left| d_i - \hat{d}_i \right|^2}
$$

3. Average Log10 Error: 
$$ 
\quad \text{Average Log10 Error} = \frac{1}{M} \sum_{i=1}^{M} \left| \log_{10}(d_i) - \log_{10}(\hat{d}_i) \right| 
$$

4. Threshold Accuracy $(\delta^n)$:
$$
\begin{align*}
\text{Percentage of pixels where} \quad \max \left( \frac{d_i}{\hat{d}_i}, \frac{\hat{d}_i}{d_i} \right) < 1.25^n \quad \text{for } n = 1, 2, 3 \\
\delta^n &: \text{Threshold Accuracy for } n = 1, 2, 3 \\
d_i &: \text{Ground Truth Depth at pixel } i \\
\hat{d}_i &: \text{Predicted Depth at pixel } i \\
M &: \text{Total Number of Pixels in the Image}
\end{align*}
$$

5. Mean Relative Improvement across Datasets (mRID):
$$
\quad \text{mRID} = \frac{1}{M} \sum_{i=1}^{M} \text{RID}_i
$$
6. Mean Relative Improvement across Metrics (mRI$\theta$)
$$
\quad \text{mRI}\theta = \frac{1}{N} \sum_{j=1}^{N} \text{RI}\theta_j
$$

7. Relative Improvement (RI) for lower-is-better metrics:
$$
 \quad \text{RI} = \frac{r - t}{r}
$$


8. Relative Improvement (RI) for higher-is-better metrics:
$$ \quad \text{RI} = \frac{t - r}{r} $$
$$
\\ r: \text{Reference Score} \\ t: \text{Target Score} $$


- ZoeDepth는 scale-invariant log loss를 사용하여 깊이 추정의 정확도 측정
	- 이 loss function은 깊이 추정에서의 스케일 불변성을 보장하여, 다양한 크기의 객체에 대한 깊이 추정을 일관되게 수행할 수 있도록 함
- 모델의 성능 평가에는 정확도, 정밀도, 재현율과 같은 표준 메트릭스가 사용



Includes three main models :

- ZoeD-M12-N
- ZoeD-M12-K
- ZoeD-M12-NK

Performance (REL):

|Model|Backbone|NYU|SUN RGBD|iBims-1|DIODE Indoor|Hypersim|
|:-:|:-:|:-:|---|---|---|---|
|ZoeD-M12-N|BEiT-L-384|0.075|0.119|0.169|0.327|0.410|

|Model|Backbone|NYU|SUN RGBD|iBims-1|DIODE Indoor|Hypersim|Virtual KITTI 2|DDAD|DIML Outdoor|DIODE Outdoor|
|:-:|:-:|:-:|---|---|---|---|---|---|---|---|
|ZoeD-M12-NK|BEiT-L-384|0.077|0.123|0.186|0.331|0.419|0.105|0.138|0.641|0.757|

|Model|Backbone|Virtual KITTI 2|DDAD|DIML Outdoor|DIODE Outdoor|
|:-:|:-:|---|---|---|---|
|ZoeD-M12-K|BEiT-L-384|0.100|0.129|1.921|0.852|




